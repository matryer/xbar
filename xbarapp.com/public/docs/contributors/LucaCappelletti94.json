{
	"person": {
		"name": "Luca Cappelletti",
		"githubUsername": "LucaCappelletti94",
		"imageURL": "https://avatars.githubusercontent.com/u/7738570?v=4",
		"bio": "Waiting for CRISPR vim macros.",
		"primary": true
	},
	"plugins": [
		{
			"files": [
				{
					"path": "Dev/alexa_rank.1h.py",
					"filename": "alexa_rank.1h.py",
					"content": "#!/usr/bin/python\n# coding=utf-8\n#\n# \u003cbitbar.title\u003eAlexa rank checker\u003c/bitbar.title\u003e\n# \u003cbitbar.version\u003ev1.1\u003c/bitbar.version\u003e\n# \u003cbitbar.author\u003eLuca Cappelletti\u003c/bitbar.author\u003e\n# \u003cbitbar.author.github\u003eLucaCappelletti94\u003c/bitbar.author.github\u003e\n# \u003cbitbar.desc\u003eDisplays Alexa rank from given websites\u003c/bitbar.desc\u003e\n# \u003cbitbar.image\u003ehttp://i.imgur.com/30YjoCF.jpg\u003c/bitbar.image\u003e\n# \u003cbitbar.dependencies\u003epython\u003c/bitbar.dependencies\u003e\n#\n# by Luca Cappelletti\n\nimport urllib\nimport sys\nimport xml.etree.ElementTree as ET\nimport time\nimport json\nimport os\nfrom urlparse import urlparse\n\nreload(sys)\nsys.setdefaultencoding('utf8')\n\n\nclass Alexa:\n    api_url = \"http://data.alexa.com/data\"\n    is_online_test_url = \"http://google.com\"\n    cache_file_dir = \"/tmp/alexa_rank_cache\"\n    cache_file_name = \"/tmp/alexa_rank_cache/alexa_cache.json\"\n    popularity_icon = \" ğŸŒ \"\n    black_popularity_icon = \" â™¥ \"\n    delta_icon = \" â‡• \"\n    default_flag_icon = \"âš‘\"\n    flags_icons = {\n        \"AU\": \"ğŸ‡¦ğŸ‡º\",\n        \"CA\": \"ğŸ‡¨ğŸ‡¦\",\n        \"CH\": \"ğŸ‡¨ğŸ‡­\",\n        \"CN\": \"ğŸ‡¨ğŸ‡³\",\n        \"DE\": \"ğŸ‡©ğŸ‡ª\",\n        \"ES\": \"ğŸ‡ªğŸ‡¸\",\n        \"FR\": \"ğŸ‡«ğŸ‡·\",\n        \"GB\": \"ğŸ‡¬ğŸ‡§\",\n        \"IL\": \"ğŸ‡®ğŸ‡±\",\n        \"IT\": \"ğŸ‡®ğŸ‡¹\",\n        \"JP\": \"ğŸ‡¯ğŸ‡µ\",\n        \"KN\": \"ğŸ‡°ğŸ‡³\",\n        \"KR\": \"ğŸ‡°ğŸ‡·\",\n        \"NO\": \"ğŸ‡³ğŸ‡´\",\n        \"NP\": \"ğŸ‡³ğŸ‡µ\",\n        \"PS\": \"ğŸ‡µğŸ‡¸\",\n        \"QA\": \"ğŸ‡¶ğŸ‡¦\",\n        \"RU\": \"ğŸ‡·ğŸ‡º\",\n        \"SS\": \"ğŸ‡¸ğŸ‡¸\",\n        \"US\": \"ğŸ‡ºğŸ‡¸\"\n    }\n\n    OFFLINE = 0\n    UNRETRIEVED_DATA = 1\n    INVALID_JSON = 2\n    UNEXISTING_FILE = 3\n    INVALID_URLS = 4\n    UNEXISTING_ERROR_ID = 5\n\n    error_messages = {\n        OFFLINE: {\n            \"en\": \"You are offline.\",\n            \"de\": \"Du bist Offline.\",\n            \"it\": \"Sei offline.\"\n        },\n        UNRETRIEVED_DATA: {\n            \"en\": \"Unable to get data for %s.\",\n            \"it\": \"Impossibile recuperare dati per %s.\"\n        },\n        INVALID_JSON: {\n            \"en\": \"The file %s does not contain valid json.\",\n            \"it\": \"Il file %s non contiene json valido.\"\n        },\n        UNEXISTING_FILE: {\n            \"en\": \"The file %s does not exist.\",\n            \"it\": \"Il file %s non esiste.\"\n        },\n        INVALID_URLS: {\n            \"en\": \"No valid urls were provided.\",\n            \"it\": \"Non son stati inseriti url validi.\"\n        },\n        UNEXISTING_ERROR_ID: {\n            \"en\": \"The given error_id %s is not valid\",\n            \"it\": \"L'error_id %s fornito non Ã¨ valido\"\n        }\n    }\n\n    website_url_list = []\n    alexa_data = {}\n    cli = 10\n    cache = True\n    max_offline_wait = 10\n    user_language = \"en\"\n    default_user_language = \"en\"\n    polling_interval = 60 * 60  # One hour\n    show_global = True\n    show_top_country = True\n    show_delta = False\n    use_black_icons = False\n\n    def __init__(self, website_url_list, cache=None, polling_interval=None, show_global=None, show_top_country=None, show_delta=None, use_black_icons=None, max_offline_wait=None, user_language=None):\n\n        if cache != None:\n            self.cache = cache\n\n        if polling_interval != None:\n            self.polling_interval = polling_interval\n\n        if show_global != None:\n            self.show_global = show_global\n\n        if show_top_country != None:\n            self.show_top_country = show_top_country\n\n        if show_delta != None:\n            self.show_delta = show_delta\n\n        if use_black_icons != None:\n            self.use_black_icons = use_black_icons\n\n        if max_offline_wait != None:\n            self.max_offline_wait = max_offline_wait\n\n        if user_language != None:\n            self.user_language = user_language\n\n        for website_url in website_url_list:\n            if self.is_valid_url(website_url):\n                self.website_url_list.append(website_url)\n\n        if len(self.website_url_list) == 0:\n            print(self.get_error_message(self.INVALID_URLS))\n            sys.exit()\n\n        self.update()\n\n    @classmethod\n    def from_url(cls, website_url, cache=None, polling_interval=None, show_global=None, show_top_country=None, show_delta=None, use_black_icons=None, max_offline_wait=None, user_language=None):\n        return cls([website_url], cache, polling_interval, show_global, show_top_country, show_delta, use_black_icons)\n\n    def get_error_message(self, error_id):\n        if error_id in self.error_messages:\n            if self.user_language in self.error_messages[error_id]:\n                return self.error_messages[error_id][self.user_language]\n            return self.error_messages[error_id][self.default_user_language]\n        print(self.get_error_message(self.UNEXISTING_ERROR_ID), error_id)\n        sys.exit(0)\n\n    def get_data(self, website_url, data):\n        return self.alexa_data[website_url][data]\n\n    def extract(self, raw_data, key, attribute):\n        return raw_data.find(key).get(attribute)\n\n    def extract_delta(self, raw_data):\n        try:\n            return int(self.extract(raw_data, \"RANK\", \"DELTA\"))\n        except AttributeError:\n            return 0\n\n    def extract_rank(self, raw_data):\n        try:\n            return int(self.extract(raw_data, \"REACH\", \"RANK\"))\n        except AttributeError:\n            return 0\n\n    def extract_country_rank(self, raw_data):\n        try:\n            return int(self.extract(raw_data, \"COUNTRY\", \"RANK\"))\n        except AttributeError:\n            return 0\n\n    def extract_country_code(self, raw_data):\n        try:\n            return self.extract(raw_data, \"COUNTRY\", \"CODE\")\n        except AttributeError:\n            return \"\"\n\n    def extract_country_name(self, raw_data):\n        try:\n            return self.extract(raw_data, \"COUNTRY\", \"NAME\")\n        except AttributeError:\n            return \"\"\n\n    def extract_url(self, raw_data):\n        try:\n            return self.extract(raw_data, \"POPULARITY\", \"URL\").strip(\"/\")\n        except AttributeError:\n            return \"\"\n\n    def build_url(self, website_url):\n        return self.api_url + \"?cli=\" + str(self.cli) + \"\u0026url=\" + website_url\n\n    def read_from_url(self, url):\n        try:\n            return urllib.urlopen(url).read()\n        except IOError:\n            return None\n\n    def get_alexa_data(self, website_url):\n        request_url = self.build_url(website_url)\n        data_xml = self.read_from_url(request_url)\n        if data_xml == None:\n            print(self.get_error_message(self.UNRETRIEVED_DATA), self.clean_url(website_url))\n            sys.exit()\n        return ET.ElementTree(ET.fromstring(data_xml)).getroot().find(\"SD\")\n\n    def update_url_data(self, website_url):\n        raw_data = self.get_alexa_data(website_url)\n        self.alexa_data[website_url] = {\n            \"delta\": self.extract_delta(raw_data),\n            \"global_rank\": self.extract_rank(raw_data),\n            \"top_country_rank\": self.extract_country_rank(raw_data),\n            \"top_country_code\": self.extract_country_code(raw_data),\n            \"top_country_name\": self.extract_country_name(raw_data),\n            \"url\": self.extract_url(raw_data),\n            \"last_update\": time.time()\n        }\n\n    def save_data_to_cache(self):\n        if not os.path.exists(self.cache_file_dir):\n            os.makedirs(self.cache_file_dir)\n        with open(self.cache_file_name, 'w') as outfile:\n            json.dump(self.alexa_data, outfile)\n\n    def load_data_from_cache(self):\n        if os.path.exists(self.cache_file_name):\n            with open(self.cache_file_name, 'r') as outfile:\n                try:\n                    return json.load(outfile)\n                except ValueError:\n                    os.remove(self.cache_file_name)\n                    pass\n        return {}\n\n    def is_valid_url(self, website_url):\n        test = urlparse(website_url)\n        if test.netloc == \"\":\n            return False\n        return True\n\n    def is_user_online(self):\n        if self.read_from_url(self.is_online_test_url) == None:\n            return False\n        return True\n\n    def is_url_cached(self, website_url):\n        if (website_url in self.alexa_data):\n            if(self.get_data(website_url, \"last_update\") \u003e time.time() - self.polling_interval):\n                return True\n        return False\n\n    def update(self):\n        if self.cache:\n            self.alexa_data = self.load_data_from_cache()\n        if self.is_user_online():\n            for website_url in self.website_url_list:\n                if not self.is_url_cached(website_url):\n                    self.update_url_data(website_url)\n        if(len(self.alexa_data) == 0):\n            seconds_waited = 0\n            while(not self.is_user_online() and self.max_offline_wait \u003e seconds_waited):\n                time.sleep(1)\n                seconds_waited = seconds_waited + 1\n            if(self.max_offline_wait \u003e seconds_waited):\n                self.update()\n            else:\n                print(self.get_error_message(self.OFFLINE))\n                sys.exit()\n        if self.cache:\n            self.save_data_to_cache()\n\n    def get_global_alexa_rank(self, website_url):\n        return self.get_data(website_url, \"global_rank\")\n\n    def get_top_country_alexa_rank(self, website_url):\n        return self.get_data(website_url, \"top_country_rank\")\n\n    def get_alexa_delta(self, website_url):\n        return self.get_data(website_url, \"delta\")\n\n    def get_top_country_alexa_code(self, website_url):\n        return self.get_data(website_url, \"top_country_code\")\n\n    def get_popularity_icon(self):\n        if self.use_black_icons == False:\n            return self.popularity_icon\n        return self.black_popularity_icon\n\n    def get_flag_icon(self, code):\n        if self.use_black_icons == False and code in self.flags_icons:\n            return self.flags_icons[code]\n        return self.default_flag_icon + \" \" + code + \": \"\n\n    def clean_url(self, website_url):\n        if website_url not in self.alexa_data or self.alexa_data[website_url][\"url\"] == \"\":\n            website_url = website_url.replace(\"http://\", \"\")\n            website_url = website_url.replace(\"https://\", \"\")\n            website_url = website_url.replace(\"www.\", \"\")\n            return website_url\n        return self.alexa_data[website_url][\"url\"]\n\n    def build_bitbar(self):\n        for website_url in self.website_url_list:\n            bitbar = self.clean_url(website_url) + \":\"\n            if self.show_global:\n                bitbar = bitbar + self.get_popularity_icon() + str(self.get_global_alexa_rank(website_url)) + \" \"\n            if self.show_top_country:\n                bitbar = bitbar + self.get_flag_icon(self.get_top_country_alexa_code(website_url)) + \\\n                    str(self.get_top_country_alexa_rank(website_url))\n            if self.show_delta:\n                bitbar = bitbar + self.delta_icon + str(self.get_alexa_delta(website_url))\n            print(bitbar)\n            print(\"---\")\n\n###################\n#  USAGE EXAMPLES #\n###################\n\n# With single url\n# myAlexa = Alexa.from_url(\"https://twitchtimer.com\")\n\n# Full parameters bonanza\n#\n# cache: put this to true to cache to /tmp/alexa_rank_cache/alexa_cache.json\n# polling_interval: seconds of duration of caching file\n# show_global: put this to true to show the global rank\n# show_top_country: put this to true to show the top country rank\n# show_delta: put this to true to show how the website rank has varied in the last period\n# use_black_icons: for those who do not like color in their menu bar\n# max_offline_wait: how many seconds should be waited brefore triyng again to read data and eventually show an \"You are offline\" error.\n# user_language: the language in which errors and messages should be shown, if available\n#\n# myAlexa = Alexa([\"twitchtimer.com\", \"google.com\"], cache=True, polling_interval=60*60, show_global=True, show_top_country=True, show_delta=False, use_black_icons=False, max_offline_wait=15, user_language=\"en\")\n\nmyAlexa = Alexa([\"https://twitchtimer.com\"], use_black_icons=True, show_top_country=False)\nmyAlexa.build_bitbar()\n"
				}
			],
			"path": "Dev/alexa_rank.1h.py",
			"filename": "alexa_rank.1h.py",
			"dir": "Dev",
			"docsPlugin": "Dev/alexa_rank.1h.py.html",
			"docsCategory": "Dev.html",
			"pathSegments": [
				"Dev"
			],
			"categoryPathSegments": [
				{
					"path": "Dev",
					"text": "Dev",
					"isLast": true
				}
			],
			"title": "Alexa rank checker",
			"version": "v1.1",
			"author": "Luca Cappelletti",
			"authors": [
				{
					"name": "Luca Cappelletti",
					"githubUsername": "LucaCappelletti94",
					"imageURL": "https://avatars.githubusercontent.com/u/7738570?v=4",
					"bio": "Waiting for CRISPR vim macros.",
					"primary": true
				}
			],
			"desc": "Displays Alexa rank from given websites",
			"imageURL": "http://i.imgur.com/30YjoCF.jpg",
			"dependencies": [
				"python"
			],
			"aboutURL": "",
			"lastUpdated": "2021-03-08T15:21:50.710919Z",
			"vars": null
		}
	]
}